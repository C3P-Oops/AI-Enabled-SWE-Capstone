{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891b7ad0",
   "metadata": {},
   "source": [
    "# Group 3\n",
    "\n",
    "## Document Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a063ee0",
   "metadata": {},
   "source": [
    "## Imports and set up LLM client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1da085c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:36:57,374 ag_aisoftdev.utils INFO LLM Client configured provider=anthropic model=claude-sonnet-4-20250514 latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, Markdown, Code\n",
    "\n",
    "\n",
    "model_name = 'claude-sonnet-4-20250514'\n",
    "write_artifacts = True\n",
    "\n",
    "try:\n",
    "    # Assumes the notebook is in 'labs/Day_01_.../'\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "except IndexError:\n",
    "    # Fallback for different execution environments\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, prompt_enhancer\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0fb12",
   "metadata": {},
   "source": [
    "## Read in outputs from requirements generation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9ccc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the output directory based on API provider and model\n",
    "output_dir = f\"../documents\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(output_dir, \"brainstormed_features.md\"), \"r\") as f:\n",
    "    brainstormed_features = f.read()\n",
    "\n",
    "with open(os.path.join(output_dir, \"user_personas.md\"), \"r\") as f:\n",
    "    user_personas = f.read()\n",
    "    \n",
    "with open(os.path.join(output_dir, \"user_stories.json\"), \"r\") as f:\n",
    "    user_stories = f.read()\n",
    "\n",
    "with open(\"../artifacts/templates/prd_template.md\", \"r\") as f:\n",
    "    prd_template = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad7a5bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 10:39:25,510 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Simple PRD...\n"
     ]
    }
   ],
   "source": [
    "simple_prd_prompt = f\"\"\"\n",
    "You are a product manager for an employee onboarding tool. Generate a simple Product Requirements Document (PRD) based on user stories:\n",
    "\n",
    "The PRD should include the following sections:\n",
    "1. Introduction\n",
    "2. User Personas\n",
    "3. Features\n",
    "4. User Stories\n",
    "\n",
    "Please format the output as a markdown document with structured formatting, removing all ```markdown``` tags.\n",
    "\n",
    "<User Stories>\n",
    "{user_stories}\n",
    "</User Stories>\n",
    "\"\"\"\n",
    "\n",
    "enhanced_prd_prompt = prompt_enhancer(simple_prd_prompt)\n",
    "\n",
    "print(\"Generating Simple PRD...\")\n",
    "if user_stories:\n",
    "    simple_prd_output = get_completion(enhanced_prd_prompt, client, model_name, api_provider)\n",
    "\n",
    "    if write_artifacts:\n",
    "        with open(os.path.join(output_dir, \"simple_PRD.md\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(simple_prd_output)\n",
    "    else:\n",
    "        print(simple_prd_output)\n",
    "        \n",
    "else:\n",
    "    print(\"Skipping PRD generation because user stories are missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e2d0c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating PRD from Template...\n"
     ]
    }
   ],
   "source": [
    "with open(\"../artifacts/templates/prd_template.md\", \"r\") as f:\n",
    "    prd_template_content = f.read()\n",
    "\n",
    "template_prd_prompt = f'''You are a senior product manager. Using the following user stories, populate the provided Product Requirements Document (PRD) template.\n",
    "    Also, keep in mind the output of the simple PRD you generated earlier, listed below. Use some of the relevant content from that PRD to help fill in the template, especially where it aligns with the user stories.\n",
    "    In cases where the template requests information not present in the user stories, use your best judgment to fill in all reasonable details.\n",
    "    User Stories: {user_stories}\n",
    "    Simple PRD: {simple_prd_output}\n",
    "    PRD Template: {prd_template_content}'''\n",
    "\n",
    "print(\"Generating PRD from Template...\")\n",
    "if user_stories and prd_template_content:\n",
    "    prd_from_template_output = get_completion(template_prd_prompt, client, model_name, api_provider)\n",
    "\n",
    "    if write_artifacts:\n",
    "        with open(os.path.join(output_dir, \"template_PRD.md\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(prd_from_template_output)\n",
    "    else:\n",
    "        print(prd_from_template_output)\n",
    "        \n",
    "else:\n",
    "    print(\"Skipping PRD generation because user stories or template are missing.\")\n",
    "    prd_from_template_output = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bd105cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Pydantic Model for PRD ---\n",
      "\n",
      "--- Generated Pydantic Model ---\n",
      "# Generated using Claude 3.5 Sonnet by Anthropic\n",
      "\n",
      "from datetime import datetime\n",
      "from typing import List, Optional, Dict, Any\n",
      "from enum import Enum\n",
      "from pydantic import BaseModel, Field\n",
      "\n",
      "\n",
      "class DocumentStatus(str, Enum):\n",
      "    \"\"\"Enumeration for document status values.\"\"\"\n",
      "    DRAFT = \"Draft\"\n",
      "    REVIEW = \"Review\"\n",
      "    APPROVED = \"Approved\"\n",
      "    FINAL = \"Final\"\n",
      "\n",
      "\n",
      "class DocumentMetadata(BaseModel):\n",
      "    \"\"\"\n",
      "    Represents the metadata information for the PRD document.\n",
      "    Contains status, authorship, version, and update information.\n",
      "    \"\"\"\n",
      "    status: DocumentStatus\n",
      "    author: str\n",
      "    version: str\n",
      "    last_updated: str\n",
      "\n",
      "\n",
      "class ExecutiveSummary(BaseModel):\n",
      "    \"\"\"\n",
      "    Represents the executive summary and vision section of the PRD.\n",
      "    Provides high-level overview and product vision for stakeholders.\n",
      "    \"\"\"\n",
      "    product_description: str\n",
      "    target_users: List[str]\n",
      "    key_capabilities: List[str]\n",
      "    vision_statement: str\n",
      "\n",
      "\n",
      "class UserPersona(BaseModel):\n",
      "    \"\"\"\n",
      "    Represents a user persona with their specific challenges and needs.\n",
      "    Used to define target users and their pain points.\n",
      "    \"\"\"\n",
      "    name: str\n",
      "    role: str\n",
      "    challenges: List[str]\n",
      "\n",
      "\n",
      "class ProblemStatement(BaseModel):\n",
      "    \"\"\"\n",
      "    Represents the problem section of the PRD.\n",
      "    Defines the pain points and justification for the product.\n",
      "    \"\"\"\n",
      "    problem_description: str\n",
      "    user_personas: List[UserPersona]\n",
      "\n",
      "\n",
      "class SuccessMetric(BaseModel):\n",
      "    \"\"\"\n",
      "    Represents a success metric with its KPI and target value.\n",
      "    Used to measure product success and performance.\n",
      "    \"\"\"\n",
      "    goal: str\n",
      "    kpi: str\n",
      "    target: str\n",
      "\n",
      "\n",
      "class AcceptanceCriteria(BaseModel):\n",
      "    \"\"\"\n",
      "    Represents acceptance criteria for a user story.\n",
      "    Defines the conditions that must be met for story completion.\n",
      "    \"\"\"\n",
      "    given: str\n",
      "    when: str\n",
      "    then: str\n",
      "\n",
      "\n",
      "class UserStory(BaseModel):\n",
      "    \"\"\"\n",
      "    Represents a user story with its acceptance criteria.\n",
      "    Defines functional requirements from user perspective.\n",
      "    \"\"\"\n",
      "    story_id: str\n",
      "    title: str\n",
      "    description: str\n",
      "    acceptance_criteria: List[AcceptanceCriteria]\n",
      "\n",
      "\n",
      "class Epic(BaseModel):\n",
      "    \"\"\"\n",
      "    Represents an epic containing multiple related user stories.\n",
      "    Groups related functionality into manageable development units.\n",
      "    \"\"\"\n",
      "    epic_id: str\n",
      "    name: str\n",
      "    description: str\n",
      "    user_stories: List[UserStory]\n",
      "\n",
      "\n",
      "class FunctionalRequirements(BaseModel):\n",
      "    \"\"\"\n",
      "    Represents the functional requirements section of the PRD.\n",
      "    Contains all epics and user stories defining what the product must do.\n",
      "    \"\"\"\n",
      "    epics: List[Epic]\n",
      "\n",
      "\n",
      "class NonFunctionalRequirement(BaseModel):\n",
      "    \"\"\"\n",
      "    Represents a non-functional requirement.\n",
      "    Defines system qualities like performance, security, and scalability.\n",
      "    \"\"\"\n",
      "    category: str\n",
      "    description: str\n",
      "    criteria: Optional[str] = None\n",
      "\n",
      "\n",
      "class ReleaseMilestone(BaseModel):\n",
      "    \"\"\"\n",
      "    Represents a release milestone with version, timeline, and features.\n",
      "    Defines the delivery schedule and feature roadmap.\n",
      "    \"\"\"\n",
      "    version: str\n",
      "    timeline: str\n",
      "    features: List[str]\n",
      "\n",
      "\n",
      "class ReleasePlan(BaseModel):\n",
      "    \"\"\"\n",
      "    Represents the release plan and milestones section.\n",
      "    Contains the high-level delivery timeline and version planning.\n",
      "    \"\"\"\n",
      "    milestones: List[ReleaseMilestone]\n",
      "\n",
      "\n",
      "class ScopeItem(BaseModel):\n",
      "    \"\"\"\n",
      "    Represents an item that is out of scope or planned for future work.\n",
      "    Helps manage expectations and prevent scope creep.\n",
      "    \"\"\"\n",
      "    title: str\n",
      "    description: str\n",
      "\n",
      "\n",
      "class ScopeManagement(BaseModel):\n",
      "    \"\"\"\n",
      "    Represents scope management including out-of-scope items and future work.\n",
      "    Defines what the product will not include and future considerations.\n",
      "    \"\"\"\n",
      "    out_of_scope_v1: List[ScopeItem]\n",
      "    future_work: List[ScopeItem]\n",
      "\n",
      "\n",
      "class AppendixItem(BaseModel):\n",
      "    \"\"\"\n",
      "    Represents an appendix item such as open questions, dependencies, assumptions, or risks.\n",
      "    Tracks important project considerations and unknowns.\n",
      "    \"\"\"\n",
      "    type: str  # \"Open Question\", \"Dependency\", \"Assumption\", \"Risk\"\n",
      "    description: str\n",
      "\n",
      "\n",
      "class Appendix(BaseModel):\n",
      "    \"\"\"\n",
      "    Represents the appendix section containing project dependencies, assumptions, and open questions.\n",
      "    Tracks important considerations that need resolution or acknowledgment.\n",
      "    \"\"\"\n",
      "    items: List[AppendixItem]\n",
      "\n",
      "\n",
      "class ProductRequirementsDocument(BaseModel):\n",
      "    \"\"\"\n",
      "    Complete Product Requirements Document model for SmartHire ATS.\n",
      "    \n",
      "    This model represents the full structure of a PRD including metadata,\n",
      "    executive summary, problem statement, goals, functional and non-functional\n",
      "    requirements, release planning, scope management, and appendix items.\n",
      "    \n",
      "    Usage:\n",
      "        prd = ProductRequirementsDocument(\n",
      "            document_metadata=metadata,\n",
      "            executive_summary=summary,\n",
      "            problem_statement=problem,\n",
      "            # ... other sections\n",
      "        )\n",
      "    \"\"\"\n",
      "    document_metadata: DocumentMetadata\n",
      "    executive_summary: ExecutiveSummary\n",
      "    problem_statement: ProblemStatement\n",
      "    success_metrics: List[SuccessMetric]\n",
      "    functional_requirements: FunctionalRequirements\n",
      "    non_functional_requirements: List[NonFunctionalRequirement]\n",
      "    release_plan: ReleasePlan\n",
      "    scope_management: ScopeManagement\n",
      "    appendix: Appendix\n",
      "    \n",
      "    class Config:\n",
      "        \"\"\"Pydantic configuration for the model.\"\"\"\n",
      "        use_enum_values = True\n",
      "        validate_assignment = True\n",
      "        extra = \"forbid\"\n"
     ]
    }
   ],
   "source": [
    "with open(\"../documents/template_PRD.md\", \"r\") as f:\n",
    "    prd_template_content = f.read()\n",
    "\n",
    "pydantic_model_prompt = f\"\"\"Generate a Pydantic model in Python for the following Product Requirements Document (PRD) using the appropriate base libraries.\n",
    "- Focus only on Version 1.0 features and requirements.\n",
    "- The model should be named 'ProductRequirementsDocument' and should accurately represent the structure and data types of the PRD.\n",
    "- The model should use appropriate types from Python's 'typing' library (e.g., List, Optional) and have fields for each major section of the PRD.\n",
    "- Each class should have a docstring explaining its purpose and usage.\n",
    "- Insert a single line comment at the top of the file indicating which model and provider were used to generate the code.\n",
    "<PRD>\n",
    "{prd_template_content}\n",
    "</PRD>\"\"\"\n",
    "\n",
    "print(\"--- Generating Pydantic Model for PRD ---\")\n",
    "if prd_template_content:\n",
    "    pydantic_model_code = get_completion(pydantic_model_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the code if it's wrapped in markdown fences\n",
    "    if '```' in pydantic_model_code:\n",
    "        pydantic_model_code = pydantic_model_code.split('```')[1].lstrip('python').strip()\n",
    "    \n",
    "    print(\"\\n--- Generated Pydantic Model ---\")\n",
    "    print(pydantic_model_code)\n",
    "\n",
    "    # Save the generated Pydantic model code to a file.\n",
    "    model_path = f\"../artifacts/{api_provider}/{model_name}/\"\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    \n",
    "    with open(os.path.join(model_path, \"prd_model.py\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(pydantic_model_code)\n",
    "else:\n",
    "    print(\"Skipping Pydantic model generation because template is missing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c46626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a prompt to generate a markdown ADR template.\n",
    "with open(\"../documents/adr_template.md\", \"r\") as f:\n",
    "    original_adr_template = f.read()\n",
    "adr_template_prompt =  prompt_enhancer(f\"\"\" Generate a markdown template for an Architecture Decision Record (ADR) that includes the following sections:\n",
    "1. Title\n",
    "2. Status (e.g., Proposed, Accepted, Deprecated)\n",
    "3. Context (the problem or forces at play)\n",
    "4. Decision (the chosen solution)\n",
    "5. Consequences (both positive and negative results of the decision)\n",
    "Here is an example of another ADR template for reference:\n",
    "{original_adr_template}\n",
    "\"\"\")\n",
    "\n",
    "print(\"--- Generating ADR Template ---\")\n",
    "adr_template_content = get_completion(adr_template_prompt, client, model_name, api_provider)\n",
    "\n",
    "# Save the artifact\n",
    "if adr_template_content:\n",
    "    with open(\"../documents/new_adr.md\", \"w\") as f:\n",
    "        f.write(adr_template_content)\n",
    "        print(\"--- Generated ADR Template ---\")\n",
    "\n",
    "with open(\"../documents/new_adr.md\", \"r\") as f:\n",
    "    new_adr_template = f.read()\n",
    "\n",
    "new_adr_prompt = prompt_enhancer(f\"\"\"\n",
    "    Research and compare database options suitable for our new hire onboarding tool that requires high \n",
    "    availability, scalability, and strong consistency. Provide a brief overview of each option, including their pros and cons, \n",
    "    and recommend the best choice based on these criteria. The options to consider are:\n",
    "    1. PostgreSQL (With the pgvector extension)\n",
    "    2. A Specialized Vector Database (e.g., ChromaDB, FAISS)\n",
    "    Please provide a balanced view for the specific use case of our new hire onboarding tool.\n",
    "    Your response should be very thorough and detailed, suitable for inclusion in an Architecture Decision Record (ADR).\n",
    "    <ADR Template>\n",
    "    {new_adr_template}\n",
    "    </ADR Template>\n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "print(\"--- Researching Database Options ---\")\n",
    "db_research_output = get_completion(new_adr_prompt, client, model_name, api_provider)\n",
    "if db_research_output:\n",
    "    with open(\"../documents/db_decision_adr.md\", \"w\") as f:\n",
    "        f.write(db_research_output)\n",
    "        print(\"--- Generated Database Decision ADR ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
